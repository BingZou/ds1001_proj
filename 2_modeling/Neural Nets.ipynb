{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('data_test.p')\n",
    "\n",
    "object_cols = list(test.dtypes[test.dtypes == type(object())].index)\n",
    "drop_cols = object_cols + ['date', 'average_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('data_train.p').drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop('stars', axis=1)\n",
    "mean = train_X.mean()\n",
    "std = train_X.std()\n",
    "\n",
    "def transform(data):\n",
    "    return ((data - mean)/std).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = transform(train_X)\n",
    "test = pd.read_pickle('data_test.p').drop(drop_cols, axis=1)\n",
    "val = pd.read_pickle('data_val.p').drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "train_y = train['stars']\n",
    "val_X = transform(val.drop('stars', axis=1))\n",
    "val_y = val['stars']\n",
    "\n",
    "def get_preds(clf):\n",
    "    preds = clf.predict(val_X)\n",
    "    preds[preds > 5] = 5\n",
    "    preds[preds < 1] = 1\n",
    "    return preds\n",
    "\n",
    "def get_accuracy(solver, alpha, hidden_layer_sizes, activation='relu', batch_size=200, \n",
    "                 learning_rate='constant'):\n",
    "    clf = MLPRegressor(solver=solver, alpha=alpha, hidden_layer_sizes=hidden_layer_sizes)\n",
    "    clf.fit(train_X, train_y)\n",
    "    return np.mean((get_preds(clf) - val_y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4900943810264935\n",
      "1.4802598046420592\n",
      "1.4885726264549823\n",
      "1.4970355466418703\n",
      "1.4884239489758369\n",
      "1.485299627797674\n",
      "1.504058780175919\n",
      "1.4849604291674259\n"
     ]
    }
   ],
   "source": [
    "n = train_X.shape[1]\n",
    "hidden_layers = []\n",
    "\n",
    "for i in range(2, 10):\n",
    "    hidden_layers.append(tuple(np.linspace(101, 1, i).round().astype(int)[1:-1]))\n",
    "\n",
    "hidden_layer_accuracies = []\n",
    "# these accuracies perform comparably to the smaller sized layers\n",
    "for sizes in hidden_layers:\n",
    "    accuracy = get_accuracy(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=sizes)\n",
    "    print(accuracy)\n",
    "    hidden_layer_accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4773759104699247\n",
      "1.4787658632249203\n",
      "1.4802370520965316\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = [(5,2), (5), (5, 3, 2)]\n",
    "\n",
    "accuracies = []\n",
    "for sizes in hidden_layers:\n",
    "    accuracy = get_accuracy(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=sizes)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4901187545606067\n"
     ]
    }
   ],
   "source": [
    "# accuracy for 0 hidden layer (i.e. logistic regression)\n",
    "accuracy = get_accuracy(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=())\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.548369652113151\n",
      "1.7454044534779938\n"
     ]
    }
   ],
   "source": [
    "# results of baseline, using either average stars of the user or restaurant\n",
    "print(np.mean((test.avg_stars_x - test['stars']) ** 2))\n",
    "print(np.mean((test.avg_stars_y - test['stars']) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation           tanh\n",
      "solver                sgd\n",
      "alpha               1e-05\n",
      "batch_size            200\n",
      "learning_rate    adaptive\n",
      "accuracy          1.49052\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "activation             relu\n",
      "solver                  sgd\n",
      "alpha                0.0001\n",
      "batch_size              100\n",
      "learning_rate    invscaling\n",
      "accuracy            1.48708\n",
      "Name: 1, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver               adam\n",
      "alpha               1e-05\n",
      "batch_size            200\n",
      "learning_rate    constant\n",
      "accuracy          1.47564\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver                sgd\n",
      "alpha               1e-05\n",
      "batch_size            100\n",
      "learning_rate    constant\n",
      "accuracy          1.48503\n",
      "Name: 3, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver              lbfgs\n",
      "alpha               1e-05\n",
      "batch_size            300\n",
      "learning_rate    adaptive\n",
      "accuracy          1.47742\n",
      "Name: 4, dtype: object\n",
      "\n",
      "\n",
      "activation           tanh\n",
      "solver                sgd\n",
      "alpha              0.0001\n",
      "batch_size            200\n",
      "learning_rate    adaptive\n",
      "accuracy           1.4918\n",
      "Name: 5, dtype: object\n",
      "\n",
      "\n",
      "activation         logistic\n",
      "solver                  sgd\n",
      "alpha                 1e-05\n",
      "batch_size              200\n",
      "learning_rate    invscaling\n",
      "accuracy            1.49009\n",
      "Name: 6, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver              lbfgs\n",
      "alpha               0.001\n",
      "batch_size            300\n",
      "learning_rate    constant\n",
      "accuracy          1.47518\n",
      "Name: 7, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver                sgd\n",
      "alpha              0.0001\n",
      "batch_size            200\n",
      "learning_rate    adaptive\n",
      "accuracy          1.48355\n",
      "Name: 8, dtype: object\n",
      "\n",
      "\n",
      "activation         logistic\n",
      "solver                lbfgs\n",
      "alpha                0.0001\n",
      "batch_size              200\n",
      "learning_rate    invscaling\n",
      "accuracy            1.48511\n",
      "Name: 9, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activations = np.array(['logistic', 'tanh', 'relu'])\n",
    "solvers = np.array(['adam', 'sgd', 'lbfgs'])\n",
    "alphas = np.array([1e-5, 1e-4, 1e-3])\n",
    "batch_sizes = np.array([100, 200, 300])\n",
    "learning_rates = np.array(['constant', 'invscaling', 'adaptive'])\n",
    "\n",
    "accuracies = pd.DataFrame(\\\n",
    "    columns=['activation', 'solver', 'alpha', 'batch_size', 'learning_rate', 'accuracy'])\n",
    "\n",
    "for i in range(10):\n",
    "    solver = np.random.choice(solvers)\n",
    "    alpha = np.random.choice(alphas)\n",
    "    activation = np.random.choice(activations)\n",
    "    batch_size = np.random.choice(batch_sizes)\n",
    "    learning_rate = np.random.choice(learning_rates)\n",
    "    \n",
    "    accuracy = get_accuracy(solver, alpha, (5), activation, batch_size, learning_rate)\n",
    "    \n",
    "    accuracies = accuracies.append({'activation': activation, 'solver': solver,\\\n",
    "        'alpha': alpha, 'batch_size': batch_size, 'learning_rate': learning_rate,\\\n",
    "        'accuracy': accuracy}, ignore_index=True)\n",
    "    print(accuracies.iloc[-1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>alpha</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>1.490520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>1.487084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>constant</td>\n",
       "      <td>1.475644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>1.485032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>1.477415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>1.491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>1.490088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>300</td>\n",
       "      <td>constant</td>\n",
       "      <td>1.475184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>1.483548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>1.485110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  activation solver    alpha batch_size learning_rate  accuracy\n",
       "0       tanh    sgd  0.00001        200      adaptive  1.490520\n",
       "1       relu    sgd  0.00010        100    invscaling  1.487084\n",
       "2       relu   adam  0.00001        200      constant  1.475644\n",
       "3       relu    sgd  0.00001        100      constant  1.485032\n",
       "4       relu  lbfgs  0.00001        300      adaptive  1.477415\n",
       "5       tanh    sgd  0.00010        200      adaptive  1.491800\n",
       "6   logistic    sgd  0.00001        200    invscaling  1.490088\n",
       "7   logistic  lbfgs  0.00100        300      constant  1.475184\n",
       "8       relu    sgd  0.00010        200      adaptive  1.483548\n",
       "9   logistic  lbfgs  0.00010        200    invscaling  1.485110"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation                           logistic\n",
      "solver                                  lbfgs\n",
      "alpha                                  0.0001\n",
      "batch_size                                100\n",
      "learning_rate                        constant\n",
      "hidden_layers    (88, 76, 64, 51, 38, 26, 14)\n",
      "accuracy                              1.48054\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver              lbfgs\n",
      "alpha              0.0001\n",
      "batch_size            200\n",
      "learning_rate    constant\n",
      "hidden_layers        (5,)\n",
      "accuracy          1.48155\n",
      "Name: 1, dtype: object\n",
      "\n",
      "\n",
      "activation                           relu\n",
      "solver                              lbfgs\n",
      "alpha                               1e-05\n",
      "batch_size                            300\n",
      "learning_rate                    adaptive\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                          1.48314\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver               adam\n",
      "alpha               0.001\n",
      "batch_size            300\n",
      "learning_rate    constant\n",
      "hidden_layers      (5, 2)\n",
      "accuracy          1.48119\n",
      "Name: 3, dtype: object\n",
      "\n",
      "\n",
      "activation           logistic\n",
      "solver                   adam\n",
      "alpha                   0.001\n",
      "batch_size                200\n",
      "learning_rate      invscaling\n",
      "hidden_layers    (76, 51, 26)\n",
      "accuracy              1.56766\n",
      "Name: 4, dtype: object\n",
      "\n",
      "\n",
      "activation           tanh\n",
      "solver              lbfgs\n",
      "alpha               1e-05\n",
      "batch_size            300\n",
      "learning_rate    adaptive\n",
      "hidden_layers      (5, 2)\n",
      "accuracy          1.48398\n",
      "Name: 5, dtype: object\n",
      "\n",
      "\n",
      "activation               relu\n",
      "solver                    sgd\n",
      "alpha                   0.001\n",
      "batch_size                300\n",
      "learning_rate      invscaling\n",
      "hidden_layers    (76, 51, 26)\n",
      "accuracy              1.52203\n",
      "Name: 6, dtype: object\n",
      "\n",
      "\n",
      "activation                       logistic\n",
      "solver                               adam\n",
      "alpha                               1e-05\n",
      "batch_size                            300\n",
      "learning_rate                    adaptive\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                          1.72529\n",
      "Name: 7, dtype: object\n",
      "\n",
      "\n",
      "activation               logistic\n",
      "solver                       adam\n",
      "alpha                       1e-05\n",
      "batch_size                    100\n",
      "learning_rate          invscaling\n",
      "hidden_layers    (81, 61, 41, 21)\n",
      "accuracy                  1.61295\n",
      "Name: 8, dtype: object\n",
      "\n",
      "\n",
      "activation           logistic\n",
      "solver                   adam\n",
      "alpha                  0.0001\n",
      "batch_size                200\n",
      "learning_rate      invscaling\n",
      "hidden_layers    (76, 51, 26)\n",
      "accuracy              1.59623\n",
      "Name: 9, dtype: object\n",
      "\n",
      "\n",
      "activation             tanh\n",
      "solver                lbfgs\n",
      "alpha                0.0001\n",
      "batch_size              300\n",
      "learning_rate    invscaling\n",
      "hidden_layers      (68, 34)\n",
      "accuracy             1.4892\n",
      "Name: 10, dtype: object\n",
      "\n",
      "\n",
      "activation                   logistic\n",
      "solver                           adam\n",
      "alpha                          0.0001\n",
      "batch_size                        300\n",
      "learning_rate              invscaling\n",
      "hidden_layers    (84, 68, 51, 34, 18)\n",
      "accuracy                      1.70707\n",
      "Name: 11, dtype: object\n",
      "\n",
      "\n",
      "activation               relu\n",
      "solver                    sgd\n",
      "alpha                   1e-05\n",
      "batch_size                300\n",
      "learning_rate      invscaling\n",
      "hidden_layers    (76, 51, 26)\n",
      "accuracy              1.52333\n",
      "Name: 12, dtype: object\n",
      "\n",
      "\n",
      "activation                   tanh\n",
      "solver                      lbfgs\n",
      "alpha                      0.0001\n",
      "batch_size                    300\n",
      "learning_rate          invscaling\n",
      "hidden_layers    (81, 61, 41, 21)\n",
      "accuracy                  1.50196\n",
      "Name: 13, dtype: object\n",
      "\n",
      "\n",
      "activation           tanh\n",
      "solver               adam\n",
      "alpha               1e-05\n",
      "batch_size            100\n",
      "learning_rate    adaptive\n",
      "hidden_layers        (5,)\n",
      "accuracy          1.48472\n",
      "Name: 14, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver               adam\n",
      "alpha               1e-05\n",
      "batch_size            200\n",
      "learning_rate    adaptive\n",
      "hidden_layers      (5, 2)\n",
      "accuracy          1.48426\n",
      "Name: 15, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver              lbfgs\n",
      "alpha              0.0001\n",
      "batch_size            200\n",
      "learning_rate    constant\n",
      "hidden_layers          ()\n",
      "accuracy           1.4901\n",
      "Name: 16, dtype: object\n",
      "\n",
      "\n",
      "activation             relu\n",
      "solver                 adam\n",
      "alpha                0.0001\n",
      "batch_size              300\n",
      "learning_rate    invscaling\n",
      "hidden_layers      (68, 34)\n",
      "accuracy            1.52786\n",
      "Name: 17, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver              lbfgs\n",
      "alpha               0.001\n",
      "batch_size            100\n",
      "learning_rate    constant\n",
      "hidden_layers          ()\n",
      "accuracy          1.49011\n",
      "Name: 18, dtype: object\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuameisel/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation                   relu\n",
      "solver                        sgd\n",
      "alpha                       0.001\n",
      "batch_size                    300\n",
      "learning_rate            adaptive\n",
      "hidden_layers    (81, 61, 41, 21)\n",
      "accuracy                   1.5762\n",
      "Name: 19, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver               adam\n",
      "alpha              0.0001\n",
      "batch_size            100\n",
      "learning_rate    adaptive\n",
      "hidden_layers        (5,)\n",
      "accuracy           1.4838\n",
      "Name: 20, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver              lbfgs\n",
      "alpha               0.001\n",
      "batch_size            300\n",
      "learning_rate    adaptive\n",
      "hidden_layers       (51,)\n",
      "accuracy          1.47877\n",
      "Name: 21, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver                sgd\n",
      "alpha               0.001\n",
      "batch_size            100\n",
      "learning_rate    constant\n",
      "hidden_layers    (68, 34)\n",
      "accuracy          1.48755\n",
      "Name: 22, dtype: object\n",
      "\n",
      "\n",
      "activation         logistic\n",
      "solver                 adam\n",
      "alpha                 0.001\n",
      "batch_size              100\n",
      "learning_rate    invscaling\n",
      "hidden_layers      (68, 34)\n",
      "accuracy            1.52956\n",
      "Name: 23, dtype: object\n",
      "\n",
      "\n",
      "activation         logistic\n",
      "solver                  sgd\n",
      "alpha                0.0001\n",
      "batch_size              300\n",
      "learning_rate    invscaling\n",
      "hidden_layers            ()\n",
      "accuracy            1.93881\n",
      "Name: 24, dtype: object\n",
      "\n",
      "\n",
      "activation                           relu\n",
      "solver                                sgd\n",
      "alpha                              0.0001\n",
      "batch_size                            200\n",
      "learning_rate                    constant\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                           1.5653\n",
      "Name: 25, dtype: object\n",
      "\n",
      "\n",
      "activation                           logistic\n",
      "solver                                  lbfgs\n",
      "alpha                                   0.001\n",
      "batch_size                                300\n",
      "learning_rate                        adaptive\n",
      "hidden_layers    (88, 76, 64, 51, 38, 26, 14)\n",
      "accuracy                              1.48126\n",
      "Name: 26, dtype: object\n",
      "\n",
      "\n",
      "activation             relu\n",
      "solver                 adam\n",
      "alpha                 1e-05\n",
      "batch_size              200\n",
      "learning_rate    invscaling\n",
      "hidden_layers          (5,)\n",
      "accuracy            1.48584\n",
      "Name: 27, dtype: object\n",
      "\n",
      "\n",
      "activation           logistic\n",
      "solver                   adam\n",
      "alpha                   0.001\n",
      "batch_size                300\n",
      "learning_rate      invscaling\n",
      "hidden_layers    (76, 51, 26)\n",
      "accuracy              1.58532\n",
      "Name: 28, dtype: object\n",
      "\n",
      "\n",
      "activation               logistic\n",
      "solver                      lbfgs\n",
      "alpha                       0.001\n",
      "batch_size                    200\n",
      "learning_rate            constant\n",
      "hidden_layers    (81, 61, 41, 21)\n",
      "accuracy                  1.49451\n",
      "Name: 29, dtype: object\n",
      "\n",
      "\n",
      "activation                               tanh\n",
      "solver                                   adam\n",
      "alpha                                   1e-05\n",
      "batch_size                                300\n",
      "learning_rate                        adaptive\n",
      "hidden_layers    (88, 76, 64, 51, 38, 26, 14)\n",
      "accuracy                              1.69703\n",
      "Name: 30, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver               adam\n",
      "alpha               1e-05\n",
      "batch_size            300\n",
      "learning_rate    constant\n",
      "hidden_layers       (51,)\n",
      "accuracy          1.49055\n",
      "Name: 31, dtype: object\n",
      "\n",
      "\n",
      "activation               logistic\n",
      "solver                      lbfgs\n",
      "alpha                       0.001\n",
      "batch_size                    300\n",
      "learning_rate            constant\n",
      "hidden_layers    (81, 61, 41, 21)\n",
      "accuracy                  1.50626\n",
      "Name: 32, dtype: object\n",
      "\n",
      "\n",
      "activation                   relu\n",
      "solver                       adam\n",
      "alpha                      0.0001\n",
      "batch_size                    300\n",
      "learning_rate            adaptive\n",
      "hidden_layers    (81, 61, 41, 21)\n",
      "accuracy                  1.67141\n",
      "Name: 33, dtype: object\n",
      "\n",
      "\n",
      "activation                   relu\n",
      "solver                      lbfgs\n",
      "alpha                       1e-05\n",
      "batch_size                    200\n",
      "learning_rate          invscaling\n",
      "hidden_layers    (81, 61, 41, 21)\n",
      "accuracy                  1.47826\n",
      "Name: 34, dtype: object\n",
      "\n",
      "\n",
      "activation           logistic\n",
      "solver                    sgd\n",
      "alpha                   1e-05\n",
      "batch_size                300\n",
      "learning_rate      invscaling\n",
      "hidden_layers    (76, 51, 26)\n",
      "accuracy              1.52185\n",
      "Name: 35, dtype: object\n",
      "\n",
      "\n",
      "activation                           relu\n",
      "solver                              lbfgs\n",
      "alpha                              0.0001\n",
      "batch_size                            200\n",
      "learning_rate                  invscaling\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                          1.48081\n",
      "Name: 36, dtype: object\n",
      "\n",
      "\n",
      "activation           tanh\n",
      "solver                sgd\n",
      "alpha               1e-05\n",
      "batch_size            100\n",
      "learning_rate    constant\n",
      "hidden_layers          ()\n",
      "accuracy          8.27605\n",
      "Name: 37, dtype: object\n",
      "\n",
      "\n",
      "activation           tanh\n",
      "solver              lbfgs\n",
      "alpha               0.001\n",
      "batch_size            200\n",
      "learning_rate    adaptive\n",
      "hidden_layers      (5, 2)\n",
      "accuracy          1.48018\n",
      "Name: 38, dtype: object\n",
      "\n",
      "\n",
      "activation           tanh\n",
      "solver              lbfgs\n",
      "alpha               0.001\n",
      "batch_size            200\n",
      "learning_rate    adaptive\n",
      "hidden_layers       (51,)\n",
      "accuracy          1.48036\n",
      "Name: 39, dtype: object\n",
      "\n",
      "\n",
      "activation                               relu\n",
      "solver                                  lbfgs\n",
      "alpha                                   1e-05\n",
      "batch_size                                100\n",
      "learning_rate                        adaptive\n",
      "hidden_layers    (88, 76, 64, 51, 38, 26, 14)\n",
      "accuracy                               1.4952\n",
      "Name: 40, dtype: object\n",
      "\n",
      "\n",
      "activation             tanh\n",
      "solver                lbfgs\n",
      "alpha                0.0001\n",
      "batch_size              300\n",
      "learning_rate    invscaling\n",
      "hidden_layers        (5, 2)\n",
      "accuracy            1.48374\n",
      "Name: 41, dtype: object\n",
      "\n",
      "\n",
      "activation                       relu\n",
      "solver                          lbfgs\n",
      "alpha                          0.0001\n",
      "batch_size                        300\n",
      "learning_rate              invscaling\n",
      "hidden_layers    (84, 68, 51, 34, 18)\n",
      "accuracy                      1.50449\n",
      "Name: 42, dtype: object\n",
      "\n",
      "\n",
      "activation             relu\n",
      "solver                lbfgs\n",
      "alpha                0.0001\n",
      "batch_size              300\n",
      "learning_rate    invscaling\n",
      "hidden_layers        (5, 2)\n",
      "accuracy            1.48267\n",
      "Name: 43, dtype: object\n",
      "\n",
      "\n",
      "activation                           tanh\n",
      "solver                              lbfgs\n",
      "alpha                               1e-05\n",
      "batch_size                            100\n",
      "learning_rate                  invscaling\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                          1.48208\n",
      "Name: 44, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver              lbfgs\n",
      "alpha              0.0001\n",
      "batch_size            200\n",
      "learning_rate    adaptive\n",
      "hidden_layers       (51,)\n",
      "accuracy          1.47898\n",
      "Name: 45, dtype: object\n",
      "\n",
      "\n",
      "activation                           tanh\n",
      "solver                                sgd\n",
      "alpha                               1e-05\n",
      "batch_size                            200\n",
      "learning_rate                  invscaling\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                          1.63364\n",
      "Name: 46, dtype: object\n",
      "\n",
      "\n",
      "activation           tanh\n",
      "solver               adam\n",
      "alpha               1e-05\n",
      "batch_size            100\n",
      "learning_rate    adaptive\n",
      "hidden_layers    (68, 34)\n",
      "accuracy          1.54264\n",
      "Name: 47, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver                sgd\n",
      "alpha              0.0001\n",
      "batch_size            100\n",
      "learning_rate    adaptive\n",
      "hidden_layers    (68, 34)\n",
      "accuracy          1.49417\n",
      "Name: 48, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver               adam\n",
      "alpha              0.0001\n",
      "batch_size            100\n",
      "learning_rate    constant\n",
      "hidden_layers    (68, 34)\n",
      "accuracy          1.52613\n",
      "Name: 49, dtype: object\n",
      "\n",
      "\n",
      "activation           tanh\n",
      "solver              lbfgs\n",
      "alpha               0.001\n",
      "batch_size            100\n",
      "learning_rate    constant\n",
      "hidden_layers    (68, 34)\n",
      "accuracy          1.48887\n",
      "Name: 50, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver               adam\n",
      "alpha               0.001\n",
      "batch_size            200\n",
      "learning_rate    adaptive\n",
      "hidden_layers        (5,)\n",
      "accuracy          1.48871\n",
      "Name: 51, dtype: object\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation       logistic\n",
      "solver                sgd\n",
      "alpha               1e-05\n",
      "batch_size            300\n",
      "learning_rate    adaptive\n",
      "hidden_layers          ()\n",
      "accuracy          4.53287\n",
      "Name: 52, dtype: object\n",
      "\n",
      "\n",
      "activation                           relu\n",
      "solver                              lbfgs\n",
      "alpha                               0.001\n",
      "batch_size                            100\n",
      "learning_rate                  invscaling\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                          1.50038\n",
      "Name: 53, dtype: object\n",
      "\n",
      "\n",
      "activation                           tanh\n",
      "solver                              lbfgs\n",
      "alpha                              0.0001\n",
      "batch_size                            200\n",
      "learning_rate                    constant\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                          1.49641\n",
      "Name: 54, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver               adam\n",
      "alpha              0.0001\n",
      "batch_size            100\n",
      "learning_rate    constant\n",
      "hidden_layers      (5, 2)\n",
      "accuracy          1.47876\n",
      "Name: 55, dtype: object\n",
      "\n",
      "\n",
      "activation           relu\n",
      "solver               adam\n",
      "alpha               0.001\n",
      "batch_size            200\n",
      "learning_rate    constant\n",
      "hidden_layers       (51,)\n",
      "accuracy          1.48869\n",
      "Name: 56, dtype: object\n",
      "\n",
      "\n",
      "activation                       logistic\n",
      "solver                              lbfgs\n",
      "alpha                               0.001\n",
      "batch_size                            100\n",
      "learning_rate                    constant\n",
      "hidden_layers    (87, 72, 58, 44, 30, 15)\n",
      "accuracy                          1.47969\n",
      "Name: 57, dtype: object\n",
      "\n",
      "\n",
      "activation                   logistic\n",
      "solver                          lbfgs\n",
      "alpha                          0.0001\n",
      "batch_size                        100\n",
      "learning_rate              invscaling\n",
      "hidden_layers    (84, 68, 51, 34, 18)\n",
      "accuracy                      1.52508\n",
      "Name: 58, dtype: object\n",
      "\n",
      "\n",
      "activation       logistic\n",
      "solver                sgd\n",
      "alpha               0.001\n",
      "batch_size            100\n",
      "learning_rate    constant\n",
      "hidden_layers       (51,)\n",
      "accuracy          1.48001\n",
      "Name: 59, dtype: object\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuameisel/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation                   logistic\n",
      "solver                           adam\n",
      "alpha                          0.0001\n",
      "batch_size                        100\n",
      "learning_rate              invscaling\n",
      "hidden_layers    (84, 68, 51, 34, 18)\n",
      "accuracy                      1.60712\n",
      "Name: 60, dtype: object\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d6ad8b068eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mhidden_layer_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m        \u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0maccuracies_with_hidden_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracies_with_hidden_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m        \u001b[0;34m{\u001b[0m\u001b[0;34m'activation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'solver'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'alpha'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hidden_layers'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-078cdb1878b9>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(solver, alpha, hidden_layer_sizes, activation, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     13\u001b[0m                  learning_rate='constant'):\n\u001b[1;32m     14\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0;32m--> 383\u001b[0;31m                             intercept_grads, layer_units)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0miprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mpgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[0;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0;32m--> 179\u001b[0;31m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Get loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 105\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_layers = [[5], [5, 2]]\n",
    "\n",
    "for i in range(2, 10):\n",
    "    hidden_layers.append(np.linspace(101, 1, i).round().astype(int)[1:-1])\n",
    "\n",
    "hidden_layers = np.array(hidden_layers)\n",
    "\n",
    "accuracies_with_hidden_layers = pd.DataFrame(columns=['activation', 'solver', 'alpha', \\\n",
    "    'batch_size', 'learning_rate', 'hidden_layers', 'accuracy'])\n",
    "\n",
    "for i in range(100):\n",
    "    solver = np.random.choice(solvers)\n",
    "    alpha = np.random.choice(alphas)\n",
    "    activation = np.random.choice(activations)\n",
    "    batch_size = np.random.choice(batch_sizes)\n",
    "    learning_rate = np.random.choice(learning_rates)\n",
    "    hidden_layer_sizes = tuple(np.random.choice(hidden_layers))\n",
    "    \n",
    "    accuracy = get_accuracy(\\\n",
    "        solver, alpha, hidden_layer_sizes, activation, batch_size, learning_rate)\n",
    "    \n",
    "    accuracies_with_hidden_layers = accuracies_with_hidden_layers.append(\\\n",
    "        {'activation': activation, 'solver': solver, 'alpha': alpha, 'batch_size': batch_size, \\\n",
    "         'learning_rate': learning_rate, 'hidden_layers': hidden_layer_sizes, \\\n",
    "         'accuracy': accuracy}, ignore_index=True)\n",
    "    print(accuracies_with_hidden_layers.iloc[-1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_with_hidden_layers.to_csv('nn_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_with_hidden_layers = pd.read_csv('nn_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>alpha</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(81, 61, 41, 21)</td>\n",
       "      <td>1.478256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>1.478758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(51,)</td>\n",
       "      <td>1.478774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(51,)</td>\n",
       "      <td>1.478978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.479692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>(51,)</td>\n",
       "      <td>1.480007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>200</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>1.480179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>200</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(51,)</td>\n",
       "      <td>1.480361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>(88, 76, 64, 51, 38, 26, 14)</td>\n",
       "      <td>1.480544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>300</td>\n",
       "      <td>constant</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>1.481194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(88, 76, 64, 51, 38, 26, 14)</td>\n",
       "      <td>1.481259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>constant</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1.481552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.482078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>1.482672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.483137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>1.483740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1.483795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>1.483976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(5, 2)</td>\n",
       "      <td>1.484258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1.484721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1.485839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>(68, 34)</td>\n",
       "      <td>1.487550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>200</td>\n",
       "      <td>constant</td>\n",
       "      <td>(51,)</td>\n",
       "      <td>1.488686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>200</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1.488712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>(68, 34)</td>\n",
       "      <td>1.488867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(68, 34)</td>\n",
       "      <td>1.489199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>constant</td>\n",
       "      <td>()</td>\n",
       "      <td>1.490104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>()</td>\n",
       "      <td>1.490112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>constant</td>\n",
       "      <td>(51,)</td>\n",
       "      <td>1.490552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>200</td>\n",
       "      <td>constant</td>\n",
       "      <td>(81, 61, 41, 21)</td>\n",
       "      <td>1.494510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(88, 76, 64, 51, 38, 26, 14)</td>\n",
       "      <td>1.495203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>constant</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.496408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.500375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(81, 61, 41, 21)</td>\n",
       "      <td>1.501956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(84, 68, 51, 34, 18)</td>\n",
       "      <td>1.504490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>300</td>\n",
       "      <td>constant</td>\n",
       "      <td>(81, 61, 41, 21)</td>\n",
       "      <td>1.506263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(76, 51, 26)</td>\n",
       "      <td>1.521851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(76, 51, 26)</td>\n",
       "      <td>1.522033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(76, 51, 26)</td>\n",
       "      <td>1.523330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(84, 68, 51, 34, 18)</td>\n",
       "      <td>1.525084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>(68, 34)</td>\n",
       "      <td>1.526131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(68, 34)</td>\n",
       "      <td>1.527855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(68, 34)</td>\n",
       "      <td>1.529562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(68, 34)</td>\n",
       "      <td>1.542642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>constant</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.565305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>200</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(76, 51, 26)</td>\n",
       "      <td>1.567658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(81, 61, 41, 21)</td>\n",
       "      <td>1.576197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(76, 51, 26)</td>\n",
       "      <td>1.585322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(76, 51, 26)</td>\n",
       "      <td>1.596226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(84, 68, 51, 34, 18)</td>\n",
       "      <td>1.607118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(81, 61, 41, 21)</td>\n",
       "      <td>1.612947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.633637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(81, 61, 41, 21)</td>\n",
       "      <td>1.671412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(88, 76, 64, 51, 38, 26, 14)</td>\n",
       "      <td>1.697033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(84, 68, 51, 34, 18)</td>\n",
       "      <td>1.707067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(87, 72, 58, 44, 30, 15)</td>\n",
       "      <td>1.725294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>()</td>\n",
       "      <td>1.938809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>()</td>\n",
       "      <td>4.532869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>constant</td>\n",
       "      <td>()</td>\n",
       "      <td>8.276052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 activation solver    alpha  batch_size learning_rate  \\\n",
       "34          34       relu  lbfgs  0.00001         200    invscaling   \n",
       "55          55   logistic   adam  0.00010         100      constant   \n",
       "21          21   logistic  lbfgs  0.00100         300      adaptive   \n",
       "45          45       relu  lbfgs  0.00010         200      adaptive   \n",
       "57          57   logistic  lbfgs  0.00100         100      constant   \n",
       "59          59   logistic    sgd  0.00100         100      constant   \n",
       "38          38       tanh  lbfgs  0.00100         200      adaptive   \n",
       "39          39       tanh  lbfgs  0.00100         200      adaptive   \n",
       "0            0   logistic  lbfgs  0.00010         100      constant   \n",
       "36          36       relu  lbfgs  0.00010         200    invscaling   \n",
       "3            3       relu   adam  0.00100         300      constant   \n",
       "26          26   logistic  lbfgs  0.00100         300      adaptive   \n",
       "1            1       relu  lbfgs  0.00010         200      constant   \n",
       "44          44       tanh  lbfgs  0.00001         100    invscaling   \n",
       "43          43       relu  lbfgs  0.00010         300    invscaling   \n",
       "2            2       relu  lbfgs  0.00001         300      adaptive   \n",
       "41          41       tanh  lbfgs  0.00010         300    invscaling   \n",
       "20          20   logistic   adam  0.00010         100      adaptive   \n",
       "5            5       tanh  lbfgs  0.00001         300      adaptive   \n",
       "15          15   logistic   adam  0.00001         200      adaptive   \n",
       "14          14       tanh   adam  0.00001         100      adaptive   \n",
       "27          27       relu   adam  0.00001         200    invscaling   \n",
       "22          22   logistic    sgd  0.00100         100      constant   \n",
       "56          56       relu   adam  0.00100         200      constant   \n",
       "51          51   logistic   adam  0.00100         200      adaptive   \n",
       "50          50       tanh  lbfgs  0.00100         100      constant   \n",
       "10          10       tanh  lbfgs  0.00010         300    invscaling   \n",
       "16          16       relu  lbfgs  0.00010         200      constant   \n",
       "18          18   logistic  lbfgs  0.00100         100      constant   \n",
       "31          31   logistic   adam  0.00001         300      constant   \n",
       "..         ...        ...    ...      ...         ...           ...   \n",
       "29          29   logistic  lbfgs  0.00100         200      constant   \n",
       "40          40       relu  lbfgs  0.00001         100      adaptive   \n",
       "54          54       tanh  lbfgs  0.00010         200      constant   \n",
       "53          53       relu  lbfgs  0.00100         100    invscaling   \n",
       "13          13       tanh  lbfgs  0.00010         300    invscaling   \n",
       "42          42       relu  lbfgs  0.00010         300    invscaling   \n",
       "32          32   logistic  lbfgs  0.00100         300      constant   \n",
       "35          35   logistic    sgd  0.00001         300    invscaling   \n",
       "6            6       relu    sgd  0.00100         300    invscaling   \n",
       "12          12       relu    sgd  0.00001         300    invscaling   \n",
       "58          58   logistic  lbfgs  0.00010         100    invscaling   \n",
       "49          49   logistic   adam  0.00010         100      constant   \n",
       "17          17       relu   adam  0.00010         300    invscaling   \n",
       "23          23   logistic   adam  0.00100         100    invscaling   \n",
       "47          47       tanh   adam  0.00001         100      adaptive   \n",
       "25          25       relu    sgd  0.00010         200      constant   \n",
       "4            4   logistic   adam  0.00100         200    invscaling   \n",
       "19          19       relu    sgd  0.00100         300      adaptive   \n",
       "28          28   logistic   adam  0.00100         300    invscaling   \n",
       "9            9   logistic   adam  0.00010         200    invscaling   \n",
       "60          60   logistic   adam  0.00010         100    invscaling   \n",
       "8            8   logistic   adam  0.00001         100    invscaling   \n",
       "46          46       tanh    sgd  0.00001         200    invscaling   \n",
       "33          33       relu   adam  0.00010         300      adaptive   \n",
       "30          30       tanh   adam  0.00001         300      adaptive   \n",
       "11          11   logistic   adam  0.00010         300    invscaling   \n",
       "7            7   logistic   adam  0.00001         300      adaptive   \n",
       "24          24   logistic    sgd  0.00010         300    invscaling   \n",
       "52          52   logistic    sgd  0.00001         300      adaptive   \n",
       "37          37       tanh    sgd  0.00001         100      constant   \n",
       "\n",
       "                   hidden_layers  accuracy  \n",
       "34              (81, 61, 41, 21)  1.478256  \n",
       "55                        (5, 2)  1.478758  \n",
       "21                         (51,)  1.478774  \n",
       "45                         (51,)  1.478978  \n",
       "57      (87, 72, 58, 44, 30, 15)  1.479692  \n",
       "59                         (51,)  1.480007  \n",
       "38                        (5, 2)  1.480179  \n",
       "39                         (51,)  1.480361  \n",
       "0   (88, 76, 64, 51, 38, 26, 14)  1.480544  \n",
       "36      (87, 72, 58, 44, 30, 15)  1.480805  \n",
       "3                         (5, 2)  1.481194  \n",
       "26  (88, 76, 64, 51, 38, 26, 14)  1.481259  \n",
       "1                           (5,)  1.481552  \n",
       "44      (87, 72, 58, 44, 30, 15)  1.482078  \n",
       "43                        (5, 2)  1.482672  \n",
       "2       (87, 72, 58, 44, 30, 15)  1.483137  \n",
       "41                        (5, 2)  1.483740  \n",
       "20                          (5,)  1.483795  \n",
       "5                         (5, 2)  1.483976  \n",
       "15                        (5, 2)  1.484258  \n",
       "14                          (5,)  1.484721  \n",
       "27                          (5,)  1.485839  \n",
       "22                      (68, 34)  1.487550  \n",
       "56                         (51,)  1.488686  \n",
       "51                          (5,)  1.488712  \n",
       "50                      (68, 34)  1.488867  \n",
       "10                      (68, 34)  1.489199  \n",
       "16                            ()  1.490104  \n",
       "18                            ()  1.490112  \n",
       "31                         (51,)  1.490552  \n",
       "..                           ...       ...  \n",
       "29              (81, 61, 41, 21)  1.494510  \n",
       "40  (88, 76, 64, 51, 38, 26, 14)  1.495203  \n",
       "54      (87, 72, 58, 44, 30, 15)  1.496408  \n",
       "53      (87, 72, 58, 44, 30, 15)  1.500375  \n",
       "13              (81, 61, 41, 21)  1.501956  \n",
       "42          (84, 68, 51, 34, 18)  1.504490  \n",
       "32              (81, 61, 41, 21)  1.506263  \n",
       "35                  (76, 51, 26)  1.521851  \n",
       "6                   (76, 51, 26)  1.522033  \n",
       "12                  (76, 51, 26)  1.523330  \n",
       "58          (84, 68, 51, 34, 18)  1.525084  \n",
       "49                      (68, 34)  1.526131  \n",
       "17                      (68, 34)  1.527855  \n",
       "23                      (68, 34)  1.529562  \n",
       "47                      (68, 34)  1.542642  \n",
       "25      (87, 72, 58, 44, 30, 15)  1.565305  \n",
       "4                   (76, 51, 26)  1.567658  \n",
       "19              (81, 61, 41, 21)  1.576197  \n",
       "28                  (76, 51, 26)  1.585322  \n",
       "9                   (76, 51, 26)  1.596226  \n",
       "60          (84, 68, 51, 34, 18)  1.607118  \n",
       "8               (81, 61, 41, 21)  1.612947  \n",
       "46      (87, 72, 58, 44, 30, 15)  1.633637  \n",
       "33              (81, 61, 41, 21)  1.671412  \n",
       "30  (88, 76, 64, 51, 38, 26, 14)  1.697033  \n",
       "11          (84, 68, 51, 34, 18)  1.707067  \n",
       "7       (87, 72, 58, 44, 30, 15)  1.725294  \n",
       "24                            ()  1.938809  \n",
       "52                            ()  4.532869  \n",
       "37                            ()  8.276052  \n",
       "\n",
       "[61 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_with_hidden_layers.sort_values('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
